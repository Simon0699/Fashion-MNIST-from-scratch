This project is an exercise in developing a neural network from basic principals and mathematics. The two files MiniBatchGD and SGD are my implementations of a classifier for the FashionMNIST dataset. The model developed in MiniBatchGD utilizes mini-batch gradient descent to optimize the model and the model in SGD utilizes stochastic gradient descent, updating the weights at every sample. The last model found in FashionMNIST-benchmark was developed with the Keras library and uses an Adam optimizer. 
